---
title: "Food watch: detecting and characterizing eating episodes through feeding gestures"
collection: Information Fusion
permalink: https://www.sciencedirect.com/science/article/pii/S1566253517304785
excerpt: ''
date: May 2018
venue: 'Volume 41'
paperurl: 'https://www.sciencedirect.com/science/article/pii/S1566253517304785'
citation: 'Your Name, You. (2015). &quot;Paper Title Number 3.&quot; <i>Journal 1</i>. 1(3).'
---
Authors face the important issue to detect people's overeating activity, which often causes health issues, by using wrist-worn sensors. Specifically, a machine learning framework was designed to detect and accurately count the number of feeding gestures during an eating episode to characterize each eating episode with a feeding gesture count using a 6-axis inertial wrist-worn sensor. Results show optimal result for participant-dependent models. Generalization relies on a motif-based time-point fusion classification framework. Finally, mapping feeding gesture count to caloric intake, allowed to roughly estimate whether participants overate while watching television.

[Download paper here](https://www.sciencedirect.com/science/article/pii/S1566253517304785)

Recommended citation: Your Name, You. (2015). "Paper Title Number 3." <i>Journal 1</i>. 1(3).